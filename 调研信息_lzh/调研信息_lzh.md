# 可能用上的知识

------

## 问了LLM得到了技术实现流程（可参考）

### **Question：**

我参加了大创的创新训练项目。题目是《智护校园：面向大模型的校园场景多模态恶意信息实时监测与主动防御系统》。具体来说，我想做一个应用。它可以对用户在大语言模型中的输入进行实时监测，是否有恶意信息，是否校园场景下的有不正确行为（学术造假、作弊、校园诈骗），是否会泄露个人信息等。对于这些信息，我们的应用会截止其输入流入大模型，并用户发送警告。 但是我们是零基础的大二学生。为了从零开始制作出这个应用，我们该走怎样的技术路线？比如说我们应该先做什么后做什么？我们应该把我们的实现过程划分成怎样的几个阶段？

### **Answer(Deepseek)：**

针对你们的项目《智护校园：面向大模型的校园场景多模态恶意信息实时监测与主动防御系统》，结合大创项目的实施特点和零基础团队的实际情况，建议将技术路线划分为以下六个阶段，并注重阶段性成果验证与知识迭代：

#### **阶段一：基础知识学习与需求明确（1-2个月）**

#### **目标**

建立技术认知框架，明确系统边界与核心功能优先级。

1. **技术基础学习**
   - **编程语言**：快速掌握Python基础语法（推荐《Python编程：从入门到实践》+菜鸟教程），重点学习数据处理库（Pandas、NumPy）和网络请求库（Requests）。
   - **机器学习入门**：通过吴恩达《机器学习》课程了解监督学习、分类任务等概念，学习Scikit-learn工具包。
   - **大模型基础**：理解GPT、文心一言等模型的输入输出机制，学习OpenAI API调用（官方文档+快速入门案例）1314。
2. **需求细化与场景拆解**
   - 通过用户调研（问卷、访谈）明确校园场景高频风险类型（如：论文代写关键词、校园贷话术、身份证号泄露模式）。
   - 参考教育领域安全标准（如《生成式人工智能服务管理暂行办法》），确定合规性要求11。

#### **阶段二：数据集构建与标注（2-3个月）**

#### **目标**

构建针对校园场景的多模态恶意信息数据集，支撑模型训练。

1. **数据采集**
   - **文本数据**：爬取公开的校园论坛、社交媒体中高风险内容（使用Scrapy框架），合成学术造假文本（如伪造实验数据、代写广告）。
   - **图像数据**：收集校园场景敏感图片（如PS成绩单、伪造证件模板），利用GAN生成对抗样本14。
   - **结构化数据**：设计模拟用户输入表单（包含学号、手机号等敏感字段）。
2. **数据标注与增强**
   - 使用Label Studio工具标注恶意内容类别（学术造假/诈骗/隐私泄露），参考《恶意图文多模态检测方法》定义标签体系10。
   - 通过文本替换、图像加噪等方式增强数据多样性。

#### **阶段三：多模态检测模型开发（3-4个月）**

#### **目标**

搭建轻量化多模态恶意信息分类模型，兼顾实时性与准确性。

1. **技术选型**
   - **文本处理**：采用BERT或RoBERTa提取语义特征，结合规则引擎（如AC自动机）匹配高危关键词1015。
   - **图像处理**：使用轻量级CNN（如MobileNetV3）检测伪造图片，集成OCR识别敏感文字12。
   - **多模态融合**：采用注意力机制（Co-Attention）关联文本与图像特征，参考《恶意图文检测专利》实现跨模态分析1014。
2. **模型训练与优化**
   - 使用Hugging Face Transformers库微调预训练模型，优先优化召回率（避免漏检）。
   - 部署模型蒸馏技术（如TinyBERT）压缩模型体积，适配边缘设备。

#### **阶段四：实时监测系统开发（2-3个月）**

#### **目标**

构建可拦截恶意输入并反馈的可交互系统原型。

1. **前后端架构设计**
   - **前端**：用Vue.js搭建用户界面，展示拦截日志与风险提示（参考教育监管系统可视化设计11）。
   - **后端**：采用Flask/Django实现API服务，集成模型推理接口（ONNX加速）。
   - **拦截机制**：设计钩子函数（Hook）捕获大模型输入流，结合规则引擎与模型预测结果分级处理713。
2. **核心功能实现**
   - **实时检测**：通过WebSocket实现输入内容流式分析，延迟控制在200ms内。
   - **主动防御**：对高风险输入触发拦截，返回定制化警告（如“检测到论文代写关键词，请遵守学术规范”）。

#### **阶段五：系统测试与迭代（1-2个月）**

#### **目标**

验证系统鲁棒性，优化用户体验。

1. **测试方案设计**
   - **功能测试**：模拟攻击场景（如隐藏敏感词的Base64编码、图像隐写术）验证防御有效性814。
   - **性能测试**：使用JMeter压测API并发能力，优化模型推理速度。
2. **用户反馈迭代**
   - 邀请学生志愿者试用系统，收集误报/漏报案例调整阈值。
   - 增加白名单机制（如允许科研场景下的敏感词）。

#### **阶段六：部署与成果转化（1个月）**

#### **目标**

完成项目落地，形成可展示成果。

1. **部署方案**
   - 本地化部署：使用Docker容器封装系统，适配校园服务器。
   - 云服务集成：通过阿里云函数计算实现弹性扩展11。
2. **成果输出**
   - 撰写技术报告并申请软件著作权。
   - 结合《数字教育应用监管》政策，设计校园安全教育模块（如风险案例库）1114。

#### **关键风险与应对建议**

1. **技术门槛高** → 优先使用开源框架（如Hugging Face、PaddlePaddle），参与AI社区竞赛（如Kaggle）积累经验。
2. **数据获取难** → 与学校信息安全部门合作获取脱敏数据，或使用合成数据工具（如Faker库）。
3. **性能瓶颈** → 采用异步处理架构，将模型推理任务分发至Redis队列。

建议每周召开敏捷会议，使用Trello管理任务看板，保持开发节奏。初期可聚焦文本检测实现MVP（最小可行产品），再逐步扩展多模态功能。

### Answer(ChatGPT)：

下面提供一个较为详细的技术路线和分阶段实施方案，供你和你的团队参考。注意，由于你们是零基础的学生，建议先从简单的原型入手，逐步积累经验，再扩展到更复杂的多模态监测功能。

#### 1. 需求分析与技术准备

- **明确功能目标**
  - **实时监测**：对用户输入（主要是文本，后期可以扩展到图像、视频等）进行实时检测。
  - **内容分类**：判断是否存在恶意信息、学术造假、作弊、校园诈骗或泄露个人信息等行为。
  - **拦截和警告**：若检测到违规内容，及时拦截输入并向用户发出警告。
- **技术储备**
  - 学习基础：掌握 Python 编程、基本的数据结构和算法。
  - 基础理论：入门机器学习和深度学习（可参考在线课程如 Coursera、B站教学视频等），特别是自然语言处理（NLP）的基础知识。
  - 工具和框架：熟悉常用的深度学习框架（如 PyTorch 或 TensorFlow）、NLP 库（如 Hugging Face Transformers）以及 Web 后端框架（如 Flask 或 Django）。

#### 2. 数据采集与预处理

- **数据收集**
  - 收集文本数据：从公开数据集、网络爬虫或者校园安全案例中收集相关文本数据。
  - 多模态数据（后期扩展）：图片、视频等数据，可以从网络或者公开数据集中获取。
- **数据标注**
  - 定义数据标签：例如“恶意信息”、“学术造假”、“正常”等。
  - 制定标注规范：建议先从少量样本开始，手动标注，构建一个初步数据集，后期逐步扩大数据量。
- **数据预处理**
  - 文本：清洗、分词、去除噪音、构建词向量或利用预训练模型的 tokenization。
  - 图像（扩展时）：图像标准化、数据增强等。

#### 3. 模型选择与训练

- **选择预训练模型**
  - 对文本检测任务，可以使用预训练的语言模型（如 BERT、RoBERTa 等）进行微调。
  - 多模态检测（后期）：可以考虑使用 CLIP 等模型，将文本和图像信息进行融合。
- **模型微调与训练**
  - 基于构建的数据集进行模型微调，训练分类器，判断输入内容是否存在违规信息。
  - 模型评估：使用准确率、召回率等指标进行验证，确保模型在实际场景中有效。

#### 4. 系统设计与架构搭建

- **系统模块划分**
  - **输入监控模块**：拦截用户输入，实时传输数据给后端处理。
  - **数据处理与预处理模块**：对输入数据进行清洗、格式化。
  - **模型推理模块**：调用训练好的模型进行内容检测。
  - **警告与拦截模块**：根据检测结果，及时拦截并提示用户。
  - **日志记录与监控模块**：记录输入和检测结果，便于后续分析和模型迭代。
- **前后端设计**
  - **后端**：采用 Flask、Django 或 FastAPI 构建 API 接口，实现实时检测功能。
  - **前端**：设计简单的用户界面（例如基于 HTML/CSS/JavaScript 或利用现成的前端框架）展示警告信息，交互更友好。
  - **数据库**：用于存储日志、检测记录等数据，方便后续调试和分析。

#### 5. 系统集成与实时监控

- **实时检测与拦截**
  - 将训练好的模型部署在服务器端，实现实时文本分析。
  - 输入数据经过模型判断后，若检测到违规内容，立即中断后续处理并向用户发送警告信息。
- **多模态扩展（进阶）**
  - 在文本监控基本实现后，考虑加入图片、音频等多模态信息的检测，综合提升系统的覆盖面和准确率。

#### 6. 测试、优化与迭代

- **功能测试**
  - 分别对各模块进行单元测试、集成测试，确保各部分工作正常。
  - 收集校园用户的真实反馈，测试警告机制和实时响应。
- **性能测试**
  - 检查系统在高并发和大数据量下的响应时间，保证实时性要求。
  - 进行边界条件测试，确保系统稳定运行。
- **模型迭代**
  - 根据测试结果不断优化数据集和模型，提升检测准确率和召回率。
  - 定期更新数据标注和模型训练，以适应不断变化的恶意信息模式。

#### 7. 部署与维护

- **部署方案**
  - 可部署在校园服务器、云平台或者边缘设备上。
  - 注意数据安全和隐私保护，确保系统本身不成为新的安全隐患。
- **后期维护**
  - 建立监控机制，实时监测系统运行状态和异常情况。
  - 定期进行安全审计和系统升级，保持与最新技术接轨。

#### 总结

建议你们按照以下阶段进行项目开发：

1. **需求分析与基础学习**：明确项目目标、技术选型，并进行相关理论和工具的学习。
2. **数据采集与预处理**：构建和标注数据集，为模型训练做准备。
3. **模型训练与验证**：选择合适的预训练模型进行微调，构建文本分类器，后期扩展至多模态。
4. **系统设计与集成开发**：搭建系统架构，完成前后端集成，实现实时监控与拦截功能。
5. **测试、优化与部署**：通过系统测试和用户反馈不断优化，最终部署并进行后续维护。

这种逐步实现的方法既符合初学者的节奏，又能够逐步构建出一个较为完整的实时监测系统。希望这条路线能帮助你们更好地规划项目进程，并在大创项目中取得好成绩。

------



## LLM-Guard 可以参考

LLM-Guard是一个工具。通过提供清理、检测有害语言、防止数据泄露和抵抗即时注入攻击，LLM-Guard 确保您的交互LLMs保持安全。

**github：**[https://github.com/protectai/llm-guard](https://github.com/protectai/llm-guard)

**论文：**[LLMGuard: Guarding Against Unsafe LLM Behavior](https://arxiv.org/abs/2403.00826)

![](.\image\1.png)

**数据集：**



------


## NLP（自然语言处理）

**课程资料：**[吴恩达深度学习课程第五课](https://www.bilibili.com/video/BV1F4411y7BA)

**需要学会：**

- RNN的BPTT手动推导（理解梯度爆炸和梯度消失的原因）

- RNN的两种经典变体：GRU与LSTM

- word embedding的基本知识

- seq2seq结构

**论文：**

- 最早提出Attention mechanism的论文: [ Neural Machine Translation by Jointly Learning to Align and Translate (arxiv.org)](https://arxiv.org/abs/1409.0473)
- Transformer模型经典论文：[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- BERT原始论文：[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- Bert的应用：<https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html#%E7%94%A8-BERT-fine-tune-%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8B%99>

**代码编写相关资料：**

- Pytorch框架的学习：https://pytorch.org/tutorials/beginner/basics/intro.html

- 预训练模型权重：[Models - Hugging Face](https://huggingface.co/models)

------


## LLM（大语言模型）

### 1. Transformer：

**论文：**

- [arXiv:1706.03762](https://arxiv.org/abs/1706.03762) 

- [Transformer论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.999.0.0) 

**视频资料理解：**

- [But what is a GPT? Visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M)

- [Attention in transformers, visually explained | Chapter 6, Deep Learning](https://www.youtube.com/watch?v=eMlx5fFNoYc&t=438s)

### 2. 大模型的三种架构：

大模型通常采用三种主要架构：Encoder-Only, Decoder-Only, 和 Encoder-Decoder。

#### ==Encoder-Only 架构（可能是我们要主要用的）==

**特点**：Encoder-Only 架构仅包含编码器部分。它通常用于处理那些只需要理解输入数据而不需要生成新数据的任务。这种架构通过堆叠多层编码器（通常是自注意力层和前馈神经网络层）来处理和理解输入。

**应用场景**：**文本分类**：如情感分析、意图识别等。**实体识别**：从文本中识别和分类命名实体。**特征提取**：为下游任务提取有用的特征，比如在更复杂的模型中使用。

**典型模型**：

- BERT（Bidirectional Encoder Representations from Transformers）是最著名的 Encoder-Only 架构的例子，广泛用于各种文本理解任务。

BERT的基础架构[BERT 论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1PL411M7eQ?vd_source=827e9d926cec44ef6817b376d985aae5)**完全理解BERT是怎么做预训练的**

论文地址：[arXiv:1810.04805](https://arxiv.org/abs/1810.04805)



#### ==Decoder-Only 架构==

**特点**：Decoder-Only 架构仅包含解码器部分。它设计用于生成任务，通过自回归方式逐个生成输出序列的元素。每个解码器层通常包含掩蔽的自注意力层，确保预测当前元素时只使用之前的元素，从而保持生成过程的因果关系。

**应用场景**：**文本生成**：如语言模型、机器翻译、文本摘要。**代码生成**：自动编写程序代码。**对话系统**：自动生成用户交互响应。

**典型模型**：

- GPT（Generative Pre-trained Transformer）系列是 Decoder-Only 架构的代表，广泛用于各种生成任务。
- Llama,llama2,llama3
- Qwen,Qwen2
- ....

几乎现在市面上所有的模型都是Decoder-only架构。

GPT系列的发展历史[【GPT，GPT-2，GPT-3 论文精读【论文精读】](https://www.bilibili.com/video/BV1AF411b7xQ?vd_source=827e9d926cec44ef6817b376d985aae5)**完全理解gpt是怎么做预训练的**



#### ==Encoder-Decoder 架构==

**特点**：Encoder-Decoder 架构结合了编码器和解码器两部分。编码器负责理解输入，而解码器则负责基于编码器的输出生成数据。这种架构通常在编码器和解码器之间有一种交互机制（如注意力机制），使得解码器可以更有效地利用编码器的信息。

**应用场景**：**机器翻译**：将一种语言翻译成另一种语言。**文本到语音（TTS）**：将文本转换为语音输出。**图像字幕**：生成描述图像内容的文字。

**典型模型**：

- ChatGLM 是为数不多的Encoder-Decoder 架构的生成模型